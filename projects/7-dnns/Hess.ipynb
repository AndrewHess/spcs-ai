{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "try:\n",
    "    import PIL.Image as Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "\n",
    "class DenoisingAutoencoder:\n",
    "    \n",
    "    def __init__(self, numpy_rng, theano_rng = None, input = None, n_visible = 784, n_hidden = 500, \n",
    "                 W = None, bhid = None, bvis = None):\n",
    "        \n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        # make a Theano random generator which gives symbolic random values\n",
    "        if not theano_rng:\n",
    "            theano_rng = RandomStreams(numpy_rng.randint(2**30))\n",
    "            \n",
    "        if not W:\n",
    "            initial_W = numpy.asarray(\n",
    "                numpy_rng.uniform(\n",
    "                    low  = -4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
    "                    high =  4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
    "                    size = (n_visible, n_hidden)\n",
    "                ),\n",
    "                dtype = theano.config.floatX\n",
    "            )\n",
    "            W = theano.shared(value = initial_W, name = 'W', borrow = True)\n",
    "            \n",
    "        if not bvis:\n",
    "            bvis = theano.shared(\n",
    "                value = numpy.zeros(\n",
    "                    n_visible,\n",
    "                    dtype = theano.config.floatX\n",
    "                ),\n",
    "                borrow = True\n",
    "            )\n",
    "        \n",
    "        if not bhid:\n",
    "            bhid = theano.shared(\n",
    "                value = numpy.zeros(\n",
    "                    n_hidden,\n",
    "                    dtype = theano.config.floatX\n",
    "                ),\n",
    "                name = 'b',\n",
    "                borrow = True\n",
    "            )\n",
    "        \n",
    "        self.W = W\n",
    "        \n",
    "        # b is the bias of the hidden\n",
    "        self.b = bhid\n",
    "        \n",
    "        # b_prime is the bias of the visible\n",
    "        self.b_prime = bvis\n",
    "        \n",
    "        self.W_prime = self.W.T\n",
    "        self.theano_rng = theano_rng\n",
    "        \n",
    "        # if there is no input, make a variable representing input\n",
    "        if input is None:\n",
    "            self.x = T.dmatrix(name = 'input')\n",
    "        else:\n",
    "            self.x = input\n",
    "        \n",
    "        self.params = [self.W, self.b, self.b_prime]\n",
    "        \n",
    "    def get_corrupted_input(self, input, corruption_level):\n",
    "        return self.theano_rng.binomial(size = input.shape, n = 1,\n",
    "                                        p = 1 - corruption_level,\n",
    "                                        dtype = theano.config.floatX) * input\n",
    "    \n",
    "    def get_hidden_values(self, input):\n",
    "        # get the values of the hidden layer\n",
    "        return T.nnet.sigmoid(T.dot(input, self.W) + self.b)\n",
    "    \n",
    "    def get_reconstructed_input(self, hidden):\n",
    "        # finds the reconstructed input given the hidden layer's values\n",
    "        return T.nnet.sigmoid(T.dot(hidden, self.W_prime) + self.b_prime)\n",
    "    \n",
    "    def get_cost_updates(self, corruption_level, learning_rate):\n",
    "        # computes the cost and the updates for one training step\n",
    "        \n",
    "        tilde_x = self.get_corrupted_input(self.x, corruption_level)\n",
    "        y = self.get_hidden_values(tilde_x)\n",
    "        z = self.get_reconstructed_input(y)\n",
    "        L = -T.sum(self.x * T.log(z) + (1 - self.x) * T.log(1 - z), axis = 1)\n",
    "        \n",
    "        cost = T.mean(L)\n",
    "        \n",
    "        # compute the gradients of the cost of the auto-encoder with respect to its parameters\n",
    "        gparams = T.grad(cost, self.params)\n",
    "        \n",
    "        # make the list of updates\n",
    "        updates = [\n",
    "            (param, param - learning_rate * gparam)\n",
    "            for param, gparam in zip(self.params, gparams)\n",
    "        ]\n",
    "        \n",
    "        return (cost, updates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
